# ğŸš— Self-Driving Car Simulator

A complete end-to-end deep learning project that trains a convolutional neural network (CNN) to autonomously drive a car in a simulator using behavioral cloning.  
Inspired by NVIDIAâ€™s groundbreaking research _End to End Learning for Self-Driving Cars_ (Bojarski et al., 2016).

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Project Structure](#-project-structure)
- [Installation](#-installation)
- [Usage](#-usage)
- [Model Architecture](#-model-architecture)
- [Data Processing](#-data-processing)
- [Training Process](#-training-process)
- [Testing and Simulation](#-testing-and-simulation)
- [Results](#-results)
- [Demo](#-demo)
- [Dependencies](#-dependencies)
- [Future Improvements](#-future-improvements)
- [Troubleshooting](#-troubleshooting)
- [References](#-references)

---

## ğŸ¯ Overview

This project implements an autonomous driving system using deep learning techniques. The system:

- Collects driving data from a simulator
- Trains a CNN model using behavioral cloning
- Deploys the trained model to control a virtual car in real-time
- Uses computer vision and neural networks to predict steering angles

The approach follows the **end-to-end learning paradigm** demonstrated by NVIDIA, where raw pixels are directly mapped to steering commands, eliminating the need for separate lane detection, path planning, or rule-based control.

---

## âœ¨ Features

### ğŸ§  **Deep Learning Model**
- **NVIDIA-inspired CNN architecture** for end-to-end learning  
- **Behavioral cloning** approach to learn from human driving data  
- **Real-time inference** for autonomous driving  

### ğŸ“Š **Data Processing and Augmentation**
- **Image preprocessing** (cropping, color space conversion, normalization)  
- **Data augmentation** techniques:  
  - Random panning  
  - Zoom transformations  
  - Brightness adjustments  
  - Horizontal flipping  
- **Data balancing** to handle steering angle distribution  

### ğŸ® **Real-time Simulation**
- **Socket.IO integration** for real-time communication with simulator  
- **Live telemetry processing** (speed, steering angle, camera feed)  
- **Autonomous control** with dynamic throttle adjustment  

### ğŸ“ˆ **Training and Monitoring**
- **Batch generation** for efficient training  
- **Training/validation split** for model evaluation  
- **Loss curve visualization** and monitoring  
- **Model checkpointing** and saving  

---

## ğŸ“ Project Structure

```

selfDrivingSimulator/
â”œâ”€â”€ ğŸ“„ main.py                  # Data reading example
â”œâ”€â”€ ğŸ‹ï¸ TrainingSimulation.py    # Model training pipeline
â”œâ”€â”€ ğŸ® TestSimulation.py        # Real-time simulator interface
â”œâ”€â”€ ğŸ› ï¸ utils.py                 # Utility functions and model architecture
â”œâ”€â”€ ğŸ“Š loss\_curve.png          # Training loss visualization
â”œâ”€â”€ ğŸ¤– model.h5                 # Trained model file
â”œâ”€â”€ ğŸ–¼ï¸ test.jpg                 # Test image
â”œâ”€â”€ ğŸ“ data/                    # Training data directory
â”‚   â”œâ”€â”€ driving\_log.csv         # Driving data logs
â”‚   â””â”€â”€ IMG/                     # Training images

````

---

## ğŸš€ Installation

### Prerequisites
- Python 3.7+  
- TensorFlow/Keras  
- OpenCV  
- Udacity Self-Driving Car Simulator  

### Setup
```bash
# Clone the repository
git clone https://github.com/NareshP215/Self-Driving-Car-Simulation
cd selfDrivingSimulator

# Install dependencies
pip install -r requirements.txt
````

Or install manually:

```bash
pip install tensorflow opencv-python pandas numpy matplotlib scikit-learn imgaug flask-socketio eventlet pillow
```

---

## ğŸ¯ Usage

### 1. **Data Collection**

* Launch the simulator in "Training Mode"
* Drive manually to collect training data
* Data gets saved as `driving_log.csv` with corresponding images in `IMG/`

### 2. **Model Training**

```bash
python TrainingSimulation.py
```

* Loads and balances training data
* Applies data augmentation
* Trains the CNN model
* Saves the trained model as `model.h5`
* Generates loss curve visualization

### 3. **Autonomous Driving**

```bash
python TestSimulation.py
```

* Loads the trained model
* Starts Socket.IO server on port 4567
* Connects to simulator in "Autonomous Mode"
* Processes camera feed and predicts steering angles
* Controls the car in real-time

### 4. **Simulator Setup**

1. Download Udacity Self-Driving Car Simulator
2. For training: Use "Training Mode" to collect data
3. For testing: Use "Autonomous Mode" and connect to `localhost:4567`

---

## ğŸ—ï¸ Model Architecture

This project adapts the **NVIDIA CNN architecture** introduced in *End to End Learning for Self-Driving Cars*. The model directly maps raw camera images to steering commands using an end-to-end learning approach.

### NVIDIA-Inspired CNN

* **Input:** 66Ã—200Ã—3 YUV images (cropped, normalized, resized)
* **Convolutions:** 5 layers for feature extraction
* **Fully Connected:** 3 layers for control decision
* **Output:** Single steering angle value (regression)

```python
# Convolutional Layers
Conv2D(24, (5,5), strides=(2,2), activation='elu')
Conv2D(36, (5,5), strides=(2,2), activation='elu')
Conv2D(48, (5,5), strides=(2,2), activation='elu')
Conv2D(64, (3,3), strides=(1,1), activation='elu')
Conv2D(64, (3,3), strides=(1,1), activation='elu')

# Fully Connected Layers
Flatten()
Dense(100, activation='elu')
Dense(50, activation='elu')
Dense(10, activation='elu')
Dense(1, activation='linear')   # Steering angle output
```

ğŸ“Œ **Key Insight:**
The network automatically learns road features (lane boundaries, curves, etc.) directly from steering data, without explicit labels, making it robust to varied driving conditions.

---

## ğŸ”„ Data Processing

### Image Preprocessing

1. Crop: remove sky/hood (60:135)
2. Convert RGB â†’ YUV
3. Gaussian Blur (3Ã—3 kernel)
4. Resize to 200Ã—66 pixels
5. Normalize pixel values to \[0,1]

### Data Augmentation

* Random panning
* Zooming (1.0â€“1.2x)
* Brightness variation (0.4â€“1.2x)
* Horizontal flipping with steering inversion

### Data Balancing

* Analyze steering angle distribution
* Reduce bias from straight-driving data

---

## ğŸ‹ï¸ Training Process

**Configuration:**

* Batch Size: 64
* Epochs: 10
* Steps per Epoch: 300
* Validation Steps: 200
* Optimizer: Adam (lr=0.0001)
* Loss Function: Mean Squared Error (MSE)

**Split:**

* Training: 80% with augmentation
* Validation: 20% without augmentation

**Features:**

* Real-time batch generation
* On-the-fly augmentation
* Validation monitoring
* Loss curve visualization
* Model checkpointing

---

## ğŸ® Testing and Simulation

* **Socket.IO** server for communication
* **Telemetry:** speed, steering, camera feed
* **Image preprocessing** pipeline
* **Model inference** for steering prediction
* **Dynamic throttle** control
* **Error handling** and safety

---

## ğŸ“Š Results

### Training Metrics

* Model successfully trains on simulator data
* Loss curves saved as `loss_curve.png`
* Validation loss monitoring prevents overfitting

### Performance

* Real-time inference (\~30 FPS)
* Smooth steering predictions
* Successful autonomous navigation
* Adaptive speed control


---
## ğŸ¥ Demo

### ğŸ“º Video
[![Watch the demo](https://img.youtube.com/vi/Zr84TbaDZfM/0.jpg)](https://www.youtube.com/watch?v=Zr84TbaDZfM)  
_Click the thumbnail to watch on YouTube_

---

## ğŸ“¦ Dependencies

See [`requirements.txt`](requirements.txt) for the full list.
Key libraries include:

* TensorFlow/Keras
* OpenCV
* Flask-SocketIO + Eventlet
* NumPy, Pandas, Matplotlib, Scikit-learn
* ImgAug, Pillow

---

## ğŸ”® Future Improvements

* Integrate lane detection for better road awareness
* Add traffic sign recognition
* Deploy on real-world RC car with Raspberry Pi
* Implement reinforcement learning for adaptive driving

---

## ğŸ”§ Troubleshooting

* **Model not loading:** Check file paths in `TestSimulation.py`
* **Simulator connection issues:** Ensure port 4567 is available
* **Poor driving performance:** Collect more diverse training data
* **Training errors:** Verify data paths and image integrity

---

## ğŸ“š References

- NVIDIA, 2016. *End to End Learning for Self-Driving Cars*  
[Read the paper (PDF)](end-to-end-dl-using-px.pdf)
